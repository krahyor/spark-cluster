<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>

    <!-- ApplicationMaster memory -->
    <property>
        <name>yarn.app.mapreduce.am.resource.mb</name>
        <value>1024</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.command-opts</name>
        <value>-Xmx800m</value> <!-- 80% of AM memory -->
    </property>

    <!-- Mapper memory -->
    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>2048</value>
    </property>
    <property>
        <name>mapreduce.reduce.java.opts</name>
        <value>-Xmx1600m</value> <!-- 80% of reducer memory -->
    </property>

    <!-- Parallelism -->
    <property>
        <name>mapreduce.task.io.sort.mb</name>
        <value>256</value>
    </property>
    <property>
        <name>mapreduce.job.reduces</name>
        <value>3</value> <!-- 1 reducer per worker (3 job distribute between all worker node) -->
    </property>
</configuration>
